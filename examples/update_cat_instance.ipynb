{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import uuid\n",
    "import hashlib\n",
    "import paramiko\n",
    "from pathlib import Path\n",
    "import ast\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#utility functions\n",
    "def create_sftp_session(host, port, username, key_file_path):\n",
    "    \"\"\"Create an SFTP session using SSH credentials.\"\"\"\n",
    "    key = paramiko.RSAKey.from_private_key_file(key_file_path)\n",
    "    transport = paramiko.Transport((host, port))\n",
    "    transport.connect(username=username, pkey=key)\n",
    "    sftp = paramiko.SFTPClient.from_transport(transport)\n",
    "    return sftp\n",
    "\n",
    "def generate_uuid():\n",
    "    return str(uuid.uuid4())\n",
    "\n",
    "def calculate_sha1(file_path):\n",
    "    sha1 = hashlib.sha1()\n",
    "    with open(file_path, 'rb') as f:\n",
    "        while True:\n",
    "            data = f.read(65536)  # Read in 64k chunks\n",
    "            if not data:\n",
    "                break\n",
    "            sha1.update(data)\n",
    "    return sha1.hexdigest()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_instance_data_and_upload(sftp, csv_file_path, json_file_path, upload_directory, target_directory):\n",
    "    # Load JSON data\n",
    "    with open(json_file_path, 'r') as file:\n",
    "        json_data = json.load(file)\n",
    "\n",
    "    # Extract the instance name from JSON\n",
    "    short_name = json_data.get('short_name', '')\n",
    "    \n",
    "    # Load CSV data\n",
    "    csv_data = pd.read_csv(csv_file_path)\n",
    "    \n",
    "    # Filter for the specific instance name using the extracted short name\n",
    "    filtered_csv_data = csv_data[csv_data['cat_tag'] == short_name]\n",
    "    \n",
    "    # Select only the desired columns\n",
    "    columns = [\n",
    "        'software_used', 'molecule_name', 'geometry', 'basis_set', 'charge',\n",
    "        'multiplicity', 'avas_atomic_orbitals', 'avas_minao', 'avas_ne', \n",
    "        'avas_no', 'nbasis', 'utility_scale', 'mean_field_obejct_from_fcidump'\n",
    "    ]\n",
    "    filtered_csv_data = filtered_csv_data[columns]\n",
    "\n",
    "    # Process each entry and upload files\n",
    "    instance_data = []\n",
    "    for _, row in filtered_csv_data.iterrows():\n",
    "        new_uuid = generate_uuid()\n",
    "        file_name = row['mean_field_obejct_from_fcidump']\n",
    "        local_file_path = Path(upload_directory) / (file_name + '.gz')\n",
    "        target_file_path = f\"{target_directory}{file_name}.{new_uuid}.gz\"\n",
    "\n",
    "        # Upload the file\n",
    "        sftp.put(local_file_path.as_posix(), target_file_path)\n",
    "        \n",
    "        # Proper URL for external access\n",
    "        full_url = f\"sftp://sftp.l3harris.com{target_file_path}\"\n",
    "        print(full_url)\n",
    "        checksum = calculate_sha1(local_file_path)\n",
    "\n",
    "        # Prepare the entry for JSON, excluding 'mean_field_obejct_from_fcidump'\n",
    "        # Apply ast.literal_eval then convert to string\n",
    "        if isinstance(row['geometry'], str):\n",
    "            row['geometry'] = ast.literal_eval(row['geometry'])\n",
    "        if isinstance(row['basis_set'], str):\n",
    "            try:\n",
    "                row['basis_set'] = ast.literal_eval(row['basis_set'])\n",
    "            except (SyntaxError, ValueError):\n",
    "                row['basis_set'] = row['basis_set'].strip()  # Handle whitespace or other issues\n",
    "\n",
    "        if isinstance(row['avas_atomic_orbitals'], str):\n",
    "            row['avas_atomic_orbitals'] = ast.literal_eval(row['avas_atomic_orbitals'])\n",
    "        \n",
    "        entry_features = row.to_dict()\n",
    "        entry_features.pop('mean_field_obejct_from_fcidump', None)  # Remove the file name info\n",
    "        instance_entry = {\n",
    "            \"instance_data_object_uuid\": new_uuid,\n",
    "            \"instance_data_object_url\": full_url,\n",
    "            \"instance_datta_checksum_type\": \"sha1sum\",\n",
    "            \"instance_data_checksum\": checksum,\n",
    "            \"features\": entry_features,\n",
    "            \"requirements\": {\n",
    "               \"probability_of_success\": 0.99,\n",
    "               \"time_limit_seconds\": 172800,\n",
    "               \"accuracy\": 1.0,\n",
    "               \"enery_units\": \"millihartree\",\n",
    "               \"energy_target\": 0.99\n",
    "            }\n",
    "        }\n",
    "        instance_data.append(instance_entry)\n",
    "\n",
    "    # Update the JSON data structure\n",
    "    json_data['instance_data'] = instance_data\n",
    "\n",
    "    # Optionally, write back the updated JSON data locally\n",
    "    with open(json_file_path, 'w') as file:\n",
    "        json.dump(json_data, file, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ../problem_instances/problem_instance.ru_macho.b78a10f2-ce8a-43c0-69ec-4cf666d8e85c.json...\n",
      "sftp://sftp.l3harris.com/gsee/fcidump.2_co2_0.2_old.1dc29784-ab7f-45a1-9821-31fea4363d74.gz\n",
      "sftp://sftp.l3harris.com/gsee/fcidump.7_melact_0.2_old.5dbed2ac-f9a4-4afe-9b18-f67378a51fb2.gz\n",
      "sftp://sftp.l3harris.com/gsee/fcidump.8_melact_0.2_old.587f69a8-4295-4d6d-811e-0eacfbc5f6dd.gz\n",
      "sftp://sftp.l3harris.com/gsee/fcidump.0_ru_macho_noncan_0.2_new.46aea10c-d57f-4133-9837-3c57d474d9a2.gz\n",
      "sftp://sftp.l3harris.com/gsee/fcidump.1_ru_macho_noncan_0.2_new.496aaf89-2cdf-43cf-8b25-246e915cc8b5.gz\n",
      "sftp://sftp.l3harris.com/gsee/fcidump.3_ts_ru_macho_co2_noncan_0.2_new.0d7e4a74-fd11-46e3-ba22-044a7ebc54c7.gz\n",
      "sftp://sftp.l3harris.com/gsee/fcidump.4_ts_ru_macho_co2_noncan_0.2_new.e5e63f77-dbaa-431c-a53f-93c0f4c0758d.gz\n",
      "sftp://sftp.l3harris.com/gsee/fcidump.5_ts_ru_macho_melact_noncan_0.2_new.d7bea809-6e34-49f8-8daf-8d728dd18268.gz\n",
      "sftp://sftp.l3harris.com/gsee/fcidump.6_ts_ru_macho_melact_noncan_0.2_new.73ae455f-a729-4fac-a626-5654b03c1ef5.gz\n"
     ]
    }
   ],
   "source": [
    "# Updating fe_red and ru_macho; 09/10/24\n",
    "host = 'sftp.l3harris.com'\n",
    "port = 22\n",
    "username = 'darpa-qb-zapata'\n",
    "key_file_path = '/Users/akunitsa/.ssh/darpa-qb-zapata-key.ppk' # Put the path for your private key here\n",
    "directory = '../problem_instances'  # Directory containing the JSON files\n",
    "upload_directory = './fcidumps'  # Local directory containing the new fcidump files\n",
    "csv_file_path = './catalysis_metadata_new_fcidump.csv'  # Path to the CSV file containing new data\n",
    "target_directory = '/gsee/'  # Target directory on the SFTP server\n",
    "\n",
    "# Create SFTP session\n",
    "sftp = create_sftp_session(host, port, username, key_file_path)\n",
    "\n",
    "# Iterate over all files in the problem_instances directory\n",
    "#json_file_path = os.path.join(directory, 'problem_instance.fe_red.a8895776-3583-4884-fbc7-d6f9df21a7ac.json')  # Full path to the JSON file\n",
    "json_file_path = os.path.join(directory, 'problem_instance.ru_macho.b78a10f2-ce8a-43c0-69ec-4cf666d8e85c.json')  # Full path to the JSON file\n",
    "print(f\"Processing {json_file_path}...\")\n",
    "update_instance_data_and_upload(sftp, csv_file_path, json_file_path, upload_directory, target_directory)\n",
    "\n",
    "# Close the SFTP session\n",
    "sftp.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting directory listing:\n",
      "Directory: //diff-eq\n",
      "Directory: //dynamics\n",
      "Directory: //gsee\n",
      "  File: //gsee/fcidump.0_ru_macho_noncan_0.2_new.5b0ddeb4-d577-45f1-bf68-74b8e7b1073a.gz\n",
      "  File: //gsee/fcidump.10_fecp2+_s0.5_noncan_0.2_new.e10bd99a-435c-41cd-84f1-41bd67890fc7.gz\n",
      "  File: //gsee/fcidump.11_fecp2_s0_noncan_0.2_new.b71baf3c-d5f0-4f8d-aead-648ba69a058e.gz\n",
      "  File: //gsee/fcidump.12_mo_n2_noncan_0.2_new.77c12db8-c32e-4f88-8552-9762a0fff763.gz\n",
      "  File: //gsee/fcidump.13_1_lut_ts_noncan_0.2_new.09c3ddd5-0187-46e8-95c3-157c470cb69a.gz\n",
      "  File: //gsee/fcidump.14_1_lut_prod_noncan_0.2_new.f36a9dbc-c34a-401f-8ea6-dc996d785edf.gz\n",
      "  File: //gsee/fcidump.15_1_lut_react_noncan_0.2_new.9cba211b-820c-4ad4-a050-336e8049e1c7.gz\n",
      "  File: //gsee/fcidump.16_ts_1over4a_noncan_0.2_new.4476d0ff-9618-4774-9619-e3f223249cea.gz\n",
      "  File: //gsee/fcidump.17_ts_1over4a_noncan_0.2_new.d74d0c01-8507-445b-bec1-f02bafbbfaab.gz\n",
      "  File: //gsee/fcidump.18_I_noncan_0.2_new.f6516937-6182-4dae-a39c-f94c0d72bf70.gz\n",
      "  File: //gsee/fcidump.19_I_noncan_0.2_new.53abfc75-37a3-440c-a023-6e4cbffecd6a.gz\n",
      "  File: //gsee/fcidump.1_ru_macho_noncan_0.2_new.42bb0a00-3e5c-4787-b3f3-848d953cc88f.gz\n",
      "  File: //gsee/fcidump.20_rc_noncan_0.2_new.3527a125-6e74-4df9-a9ac-ebba7d8b84ff.gz\n",
      "  File: //gsee/fcidump.21_rc_noncan_0.2_new.7fc6d81a-8e1c-436f-ade2-93aed1dfee42.gz\n",
      "  File: //gsee/fcidump.22_pc-_noncan_0.2_new.2e1dab84-5b1a-4521-8d36-78117ab88bbd.gz\n",
      "  File: //gsee/fcidump.23_pc-_noncan_0.2_new.21b0efe8-adc7-44c2-ac49-671cc4b4a1ee.gz\n",
      "  File: //gsee/fcidump.24_ts_1over2_noncan_0.2_new.b96f67e6-fafe-4ccd-ac6f-67afb52f3835.gz\n",
      "  File: //gsee/fcidump.25_ts_1over2_noncan_0.2_new.47f67a0f-a385-405d-9ac6-2e22f8ceb8e4.gz\n",
      "  File: //gsee/fcidump.26_pc_noncan_0.2_new.bed1771c-394c-44e6-93e3-ca41732326d2.gz\n",
      "  File: //gsee/fcidump.27_pc_noncan_0.2_new.98016425-092d-41a4-b397-9b4b237c582a.gz\n",
      "  File: //gsee/fcidump.28_2_noncan_0.2_new.e03635b0-a537-4a58-9f3e-c7114715e47d.gz\n",
      "  File: //gsee/fcidump.29_2_noncan_0.2_new.f7797f63-30ab-40e0-8ca6-042c9aa932b4.gz\n",
      "  File: //gsee/fcidump.30_4a_noncan_0.2_new.e701d53e-63fe-47f1-b727-39457c9207e6.gz\n",
      "  File: //gsee/fcidump.31_4a_noncan_0.2_new.21abd0b3-b2cb-4a8a-812e-a8706542f429.gz\n",
      "  File: //gsee/fcidump.32_2ru_III_3pl_noncan_0.2_new.cb60079d-5a30-4e3a-89d5-dbe95822df5e.gz\n",
      "  File: //gsee/fcidump.33_2ru_III_3pl_noncan_0.2_new.4811297e-a8df-4150-9d4d-376fd0c6e9cd.gz\n",
      "  File: //gsee/fcidump.34_3ruo_IV_2pl_noncan_0.2_new.30c3e4f9-1b24-4fe5-9cab-ad0b67e0d74b.gz\n",
      "  File: //gsee/fcidump.35_3ruo_IV_2pl_noncan_0.2_new.a2417602-4e97-4395-b3f0-1e29262c8053.gz\n",
      "  File: //gsee/fcidump.36_1ru_II_2pl_noncan_0.2_new.51f7d629-9a0e-4688-8562-59a5f0c0a404.gz\n",
      "  File: //gsee/fcidump.37_1ru_II_2pl_noncan_0.2_new.7be1766a-b3f7-4779-9a69-f4358645831b.gz\n",
      "  File: //gsee/fcidump.38_1_ts_noncan_0.2_new.46967cfc-d867-40e8-bef0-9655c46cef29.gz\n",
      "  File: //gsee/fcidump.39_1_ts_noncan_0.2_new.85d9d818-501e-4a0e-8fd8-c216ab5e3cb5.gz\n",
      "  File: //gsee/fcidump.3_ts_ru_macho_co2_noncan_0.2_new.52df89a4-7c19-4691-9fb9-3f419a13f985.gz\n",
      "  File: //gsee/fcidump.40_1_ts_noncan_0.2_new.7db0f859-073f-46af-9325-016a67229a4b.gz\n",
      "  File: //gsee/fcidump.41_1_ts_noncan_0.2_new.2f0b6ced-7831-4fe0-b95e-ce4d456c9c6b.gz\n",
      "  File: //gsee/fcidump.42_1_star_noncan_0.2_new.a722dd32-93c7-4fbd-9cf5-f1bf44b2cdae.gz\n",
      "  File: //gsee/fcidump.43_1_star_noncan_0.2_new.d9707874-28d5-48b6-824e-a2e6c8753437.gz\n",
      "  File: //gsee/fcidump.44_1_star_noncan_0.2_new.727ab190-e399-4bb6-a9b3-20ae57789bac.gz\n",
      "  File: //gsee/fcidump.45_1_star_noncan_0.2_new.e986eb83-6b9d-439e-85ca-a9b931eef4a2.gz\n",
      "  File: //gsee/fcidump.46_2_noncan_0.2_new.6bf3207c-664b-4ed3-8e74-82b42e277234.gz\n",
      "  File: //gsee/fcidump.47_2_noncan_0.2_new.fb3ecfad-6450-423e-aa58-d5cddab6f0f6.gz\n",
      "  File: //gsee/fcidump.48_2_noncan_0.2_new.dc406285-bac1-4b99-afbf-06728b7d699b.gz\n",
      "  File: //gsee/fcidump.49_2_noncan_0.2_new.af9d6a83-7898-4c13-80eb-a83a533ebf2d.gz\n",
      "  File: //gsee/fcidump.4_ts_ru_macho_co2_noncan_0.2_new.eb6978cd-4918-4a6c-8695-4fb55ed92996.gz\n",
      "  File: //gsee/fcidump.59_5_16_noncan_0.2_new.68af0b80-3d27-4aba-84f9-bcdd30a9255b.gz\n",
      "  File: //gsee/fcidump.5_ts_ru_macho_melact_noncan_0.2_new.0a27f69f-350f-4c02-b76f-8decfac09c6b.gz\n",
      "  File: //gsee/fcidump.60_5_16_noncan_0.2_new.28a7820f-63fe-4920-aeec-a7ffe7e55d83.gz\n",
      "  File: //gsee/fcidump.61_3_15_af_noncan_0.2_new.f738fcd6-7ddc-4d70-8ff9-4019e3718b04.gz\n",
      "  File: //gsee/fcidump.62_3_15_af_noncan_0.2_new.6e2bf415-6a69-4b36-ba0f-780a11cb7c0b.gz\n",
      "  File: //gsee/fcidump.63_5_15_af_ts_noncan_0.2_new.027490ba-34f9-4340-89ab-27fd110d2821.gz\n",
      "  File: //gsee/fcidump.64_5_15_af_ts_noncan_0.2_new.bae2da57-6a69-483e-95bc-b77f72ebfba8.gz\n",
      "  File: //gsee/fcidump.65_5_15_af_noncan_0.2_new.72343006-774e-4192-b481-fa840ed25573.gz\n",
      "  File: //gsee/fcidump.66_5_15_af_noncan_0.2_new.ea55abec-8253-445d-85fa-914948b5e5a5.gz\n",
      "  File: //gsee/fcidump.6_ts_ru_macho_melact_noncan_0.2_new.7bd785d9-856e-4648-8068-f5a4b418e09a.gz\n",
      "  File: //gsee/fcidump.9_mo_n2-_noncan_0.2_new.23aa47ca-9afe-4086-bd97-75de310e033e.gz\n",
      "File: //README.md\n",
      "File: //test.txt\n"
     ]
    }
   ],
   "source": [
    "def list_files_recursively(sftp, directory, prefix=''):\n",
    "    \"\"\"Recursively list all files in specified SFTP directory.\"\"\"\n",
    "    try:\n",
    "        # List all items in the directory\n",
    "        items = sftp.listdir_attr(directory)\n",
    "        for item in items:\n",
    "            # Construct full path\n",
    "            full_path = f\"{directory}/{item.filename}\"\n",
    "            if item.longname.startswith('d'):  # Check if it's a directory\n",
    "                print(f\"{prefix}Directory: {full_path}\")\n",
    "                # Recurse into the directory\n",
    "                list_files_recursively(sftp, full_path, prefix + '  ')\n",
    "            else:\n",
    "                print(f\"{prefix}File: {full_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to list directory {directory}: {e}\")\n",
    "\n",
    "def main():\n",
    "    host = 'sftp.l3harris.com'\n",
    "    port = 22\n",
    "    username = 'darpa-qb-zapata'\n",
    "    key_file_path = '../../darpa-qb-zapata-key.ppk'\n",
    "    directory = '/'  # Directory to list files from\n",
    "\n",
    "    # Create SFTP session\n",
    "    sftp = create_sftp_session(host, port, username, key_file_path)\n",
    "    \n",
    "    # Recursively list files in the specified directory\n",
    "    print(\"Starting directory listing:\")\n",
    "    list_files_recursively(sftp, directory)\n",
    "    \n",
    "    # Close the SFTP session\n",
    "    sftp.close()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
